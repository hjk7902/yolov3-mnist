{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402b6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:38:49.687681Z",
     "start_time": "2022-02-27T09:38:46.014Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_mAP(Yolo, dataset, score_threshold=0.25, iou_threshold=0.50, TEST_INPUT_SIZE=INPUT_SIZE):\n",
    "#     MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)\n",
    "#     NUM_CLASS = read_class_names(TRAIN_CLASSES)\n",
    "\n",
    "#     ground_truth_dir_path = 'mAP/ground-truth'\n",
    "#     if os.path.exists(ground_truth_dir_path): shutil.rmtree(ground_truth_dir_path)\n",
    "\n",
    "#     if not os.path.exists('mAP'): os.mkdir('mAP')\n",
    "#     os.mkdir(ground_truth_dir_path)\n",
    "\n",
    "#     print(f'\\ncalculating mAP{int(iou_threshold*100)}...\\n')\n",
    "\n",
    "#     gt_counter_per_class = {}\n",
    "#     for index in range(dataset.num_samples):\n",
    "#         ann_dataset = dataset.annotations[index]\n",
    "\n",
    "#         original_image, bbox_data_gt = dataset.parse_annotation(ann_dataset, True)\n",
    "\n",
    "#         if len(bbox_data_gt) == 0:\n",
    "#             bboxes_gt = []\n",
    "#             classes_gt = []\n",
    "#         else:\n",
    "#             bboxes_gt, classes_gt = bbox_data_gt[:, :4], bbox_data_gt[:, 4]\n",
    "#         ground_truth_path = os.path.join(ground_truth_dir_path, str(index) + '.txt')\n",
    "#         num_bbox_gt = len(bboxes_gt)\n",
    "\n",
    "#         bounding_boxes = []\n",
    "#         for i in range(num_bbox_gt):\n",
    "#             class_name = NUM_CLASS[classes_gt[i]]\n",
    "#             xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[i]))\n",
    "#             bbox = xmin + \" \" + ymin + \" \" + xmax + \" \" +ymax\n",
    "#             bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "\n",
    "#             # count that object\n",
    "#             if class_name in gt_counter_per_class:\n",
    "#                 gt_counter_per_class[class_name] += 1\n",
    "#             else:\n",
    "#                 # if class didn't exist yet\n",
    "#                 gt_counter_per_class[class_name] = 1\n",
    "#             bbox_mess = ' '.join([class_name, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "#         with open(f'{ground_truth_dir_path}/{str(index)}_ground_truth.json', 'w') as outfile:\n",
    "#             json.dump(bounding_boxes, outfile)\n",
    "\n",
    "#     gt_classes = list(gt_counter_per_class.keys())\n",
    "#     # sort the classes alphabetically\n",
    "#     gt_classes = sorted(gt_classes)\n",
    "#     n_classes = len(gt_classes)\n",
    "\n",
    "#     times = []\n",
    "#     json_pred = [[] for i in range(n_classes)]\n",
    "#     for index in range(dataset.num_samples):\n",
    "#         ann_dataset = dataset.annotations[index]\n",
    "\n",
    "#         image_name = ann_dataset[0].split('/')[-1]\n",
    "#         original_image, bbox_data_gt = dataset.parse_annotation(ann_dataset, True)\n",
    "        \n",
    "#         image = image_resize_to_squre(np.copy(original_image), [TEST_INPUT_SIZE, TEST_INPUT_SIZE])\n",
    "#         image_data = image[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "#         t1 = time.time()\n",
    "#         if YOLO_FRAMEWORK == \"tf\":\n",
    "#             pred_bbox = Yolo.predict(image_data)\n",
    "#         elif YOLO_FRAMEWORK == \"trt\":\n",
    "#             batched_input = tf.constant(image_data)\n",
    "#             result = Yolo(batched_input)\n",
    "#             pred_bbox = []\n",
    "#             for key, value in result.items():\n",
    "#                 value = value.numpy()\n",
    "#                 pred_bbox.append(value)\n",
    "        \n",
    "#         t2 = time.time()\n",
    "        \n",
    "#         times.append(t2-t1)\n",
    "        \n",
    "#         pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "#         pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "#         bboxes = postprocess_boxes(pred_bbox, original_image, TEST_INPUT_SIZE, score_threshold)\n",
    "#         bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "#         for bbox in bboxes:\n",
    "#             coor = np.array(bbox[:4], dtype=np.int32)\n",
    "#             score = bbox[4]\n",
    "#             class_ind = int(bbox[5])\n",
    "#             class_name = NUM_CLASS[class_ind]\n",
    "#             score = '%.4f' % score\n",
    "#             xmin, ymin, xmax, ymax = list(map(str, coor))\n",
    "#             bbox = xmin + \" \" + ymin + \" \" + xmax + \" \" +ymax\n",
    "#             json_pred[gt_classes.index(class_name)].append({\"confidence\": str(score), \"file_id\": str(index), \"bbox\": str(bbox)})\n",
    "\n",
    "#     ms = sum(times)/len(times)*1000\n",
    "#     fps = 1000 / ms\n",
    "\n",
    "#     for class_name in gt_classes:\n",
    "#         json_pred[gt_classes.index(class_name)].sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "#         with open(f'{ground_truth_dir_path}/{class_name}_predictions.json', 'w') as outfile:\n",
    "#             json.dump(json_pred[gt_classes.index(class_name)], outfile)\n",
    "\n",
    "#     # Calculate the AP for each class\n",
    "#     sum_AP = 0.0\n",
    "#     ap_dictionary = {}\n",
    "#     # open file to store the results\n",
    "#     with open(\"mAP/results.txt\", 'w') as results_file:\n",
    "#         results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "#         count_true_positives = {}\n",
    "#         for class_index, class_name in enumerate(gt_classes):\n",
    "#             count_true_positives[class_name] = 0\n",
    "#             # Load predictions of that class\n",
    "#             predictions_file = f'{ground_truth_dir_path}/{class_name}_predictions.json'\n",
    "#             predictions_data = json.load(open(predictions_file))\n",
    "\n",
    "#             # Assign predictions to ground truth objects\n",
    "#             nd = len(predictions_data)\n",
    "#             tp = [0] * nd # creates an array of zeros of size nd\n",
    "#             fp = [0] * nd\n",
    "#             for idx, prediction in enumerate(predictions_data):\n",
    "#                 file_id = prediction[\"file_id\"]\n",
    "#                 # assign prediction to ground truth object if any\n",
    "#                 #   open ground-truth with that file_id\n",
    "#                 gt_file = f'{ground_truth_dir_path}/{str(file_id)}_ground_truth.json'\n",
    "#                 ground_truth_data = json.load(open(gt_file))\n",
    "#                 ovmax = -1\n",
    "#                 gt_match = -1\n",
    "#                 # load prediction bounding-box\n",
    "#                 bb = [ float(x) for x in prediction[\"bbox\"].split() ] # bounding box of prediction\n",
    "#                 for obj in ground_truth_data:\n",
    "#                     # look for a class_name match\n",
    "#                     if obj[\"class_name\"] == class_name:\n",
    "#                         bbgt = [ float(x) for x in obj[\"bbox\"].split() ] # bounding box of ground truth\n",
    "#                         bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "#                         iw = bi[2] - bi[0] + 1\n",
    "#                         ih = bi[3] - bi[1] + 1\n",
    "#                         if iw > 0 and ih > 0:\n",
    "#                             # compute overlap (IoU) = area of intersection / area of union\n",
    "#                             ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "#                                             + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "#                             ov = iw * ih / ua\n",
    "#                             if ov > ovmax:\n",
    "#                                 ovmax = ov\n",
    "#                                 gt_match = obj\n",
    "\n",
    "#                 # assign prediction as true positive/don't care/false positive\n",
    "#                 if ovmax >= MINOVERLAP:# if ovmax > minimum overlap\n",
    "#                     if not bool(gt_match[\"used\"]):\n",
    "#                         # true positive\n",
    "#                         tp[idx] = 1\n",
    "#                         gt_match[\"used\"] = True\n",
    "#                         count_true_positives[class_name] += 1\n",
    "#                         # update the \".json\" file\n",
    "#                         with open(gt_file, 'w') as f:\n",
    "#                             f.write(json.dumps(ground_truth_data))\n",
    "#                     else:\n",
    "#                         # false positive (multiple detection)\n",
    "#                         fp[idx] = 1\n",
    "#                 else:\n",
    "#                     # false positive\n",
    "#                     fp[idx] = 1\n",
    "\n",
    "#             # compute precision/recall\n",
    "#             cumsum = 0\n",
    "#             for idx, val in enumerate(fp):\n",
    "#                 fp[idx] += cumsum\n",
    "#                 cumsum += val\n",
    "#             cumsum = 0\n",
    "#             for idx, val in enumerate(tp):\n",
    "#                 tp[idx] += cumsum\n",
    "#                 cumsum += val\n",
    "#             #print(tp)\n",
    "#             rec = tp[:]\n",
    "#             for idx, val in enumerate(tp):\n",
    "#                 rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "#             #print(rec)\n",
    "#             prec = tp[:]\n",
    "#             for idx, val in enumerate(tp):\n",
    "#                 prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "#             #print(prec)\n",
    "\n",
    "#             ap, mrec, mprec = voc_ap(rec, prec)\n",
    "#             sum_AP += ap\n",
    "#             text = \"{0:.3f}%\".format(ap*100) + \" = \" + class_name + \" AP  \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "\n",
    "#             rounded_prec = [ '%.3f' % elem for elem in prec ]\n",
    "#             rounded_rec = [ '%.3f' % elem for elem in rec ]\n",
    "#             # Write to results.txt\n",
    "#             results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall   :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "\n",
    "#             print(text)\n",
    "#             ap_dictionary[class_name] = ap\n",
    "\n",
    "#         results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "#         mAP = sum_AP / n_classes\n",
    "\n",
    "#         text = \"mAP = {:.3f}%, {:.2f} FPS\".format(mAP*100, fps)\n",
    "#         results_file.write(text + \"\\n\")\n",
    "#         print(text)\n",
    "        \n",
    "#         return mAP*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0786622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:38:49.688414Z",
     "start_time": "2022-02-27T09:38:46.312Z"
    }
   },
   "outputs": [],
   "source": [
    "# # measure mAP of trained custom model\n",
    "# mAP_model = Create_YOLOv3()\n",
    "# try:\n",
    "#     mAP_model.load_weights(save_directory) # use keras weights\n",
    "#     get_mAP(mAP_model, testset, score_threshold=TEST_SCORE_THRESHOLD, iou_threshold=TEST_IOU_THRESHOLD)\n",
    "# except UnboundLocalError:\n",
    "#     print(\"You don't have saved model weights to measure mAP, check TRAIN_SAVE_BEST_ONLY and TRAIN_SAVE_CHECKPOINT lines in configs.py\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590411fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:37:31.222609Z",
     "start_time": "2022-02-27T09:37:25.973Z"
    }
   },
   "outputs": [],
   "source": [
    "# yolo.save_weights(\"checkpoints/mnist_custom\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
